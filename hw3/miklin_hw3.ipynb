{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width: 100%; !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width: 100%; !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=1.0, criterion='gini',\n",
    "                 max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self._imp = self._gini_imp\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self._imp = self._entropy_imp\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self._imp = self._misclass_imp\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def _gini_imp(self, y):\n",
    "        un, counts = np.unique(y, return_counts=True)\n",
    "        return (1 - np.sum((counts / y.size) ** 2))*y.size\n",
    "\n",
    "    def _entropy_imp(self, y):\n",
    "        un, counts = np.unique(y, return_counts=True)\n",
    "        return - np.sum((counts / y.size) * np.log2(counts / y.size))*y.size\n",
    "\n",
    "    def _misclass_imp(self, y):\n",
    "        un, counts = np.unique(y, return_counts=True)\n",
    "        return (1 - np.max(counts / y.size))*y.size\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return ((1 - (((l_c / l_s)**2).sum(axis=1))).\n",
    "                reshape(-1, 1) * l_s +\n",
    "                (1 - (((r_c / r_s)**2).sum(axis=1))).\n",
    "                reshape(-1, 1) * r_s) / (l_s + r_s)\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -(((l_c/l_s) * np.log2(l_c/l_s)).sum(axis=1).\n",
    "                 reshape(-1, 1) * l_s +\n",
    "                 ((r_c/r_s) * np.log2(r_c/r_s)).sum(axis=1).\n",
    "                 reshape(-1, 1) * r_s) / (l_s + r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return ((1 - (l_c/l_s).max(axis=1)).reshape(-1, 1) * l_s +\n",
    "                (1 - (r_c/r_s).max(axis=1)).reshape(-1, 1) * r_s) / (l_s + r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        x_s, y_s = self.__sort_samples(x, y)\n",
    "        borders = np.where(y_s[1:] != y_s[:-1])[0] + 1\n",
    "\n",
    "        if len(borders) == 0:\n",
    "            return np.inf, None\n",
    "\n",
    "        counts = borders - np.append([0], borders[:-1])\n",
    "        template = np.zeros((borders.shape[0], self.num_class))\n",
    "        template[np.arange(borders.shape[0]), y_s[borders - 1]] = 1\n",
    "        matrix_counts = template * counts.reshape(-1, 1)\n",
    "\n",
    "        l_c = np.cumsum(matrix_counts, axis=0)\n",
    "        r_c = np.bincount(y_s, minlength=self.num_class) - l_c\n",
    "        l_s = borders.reshape(l_c.shape[0], 1)\n",
    "        r_s = y_s.shape[0] - l_s\n",
    "\n",
    "        gain = self.G_function(l_c, l_s, r_c, r_s)\n",
    "        indx = np.argmin(gain)\n",
    "        trh_ind = l_s[indx][0]\n",
    "\n",
    "        return gain[indx], 0.5*(x_s[trh_ind - 1] + x_s[trh_ind])\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "                (y.size < self.min_samples_split) or \\\n",
    "                (np.bincount(y).argmax() / y.size >= self.sufficient_share):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE,\n",
    "                                  np.bincount(y).argmax(),\n",
    "                                  np.bincount(y) / y.size)\n",
    "            return\n",
    "        else:\n",
    "            feature_ids = self.get_feature_ids(x.shape[1])\n",
    "            thresholds = np.array([self.__find_threshold(x[:, i], y)\n",
    "                                   for i in feature_ids])\n",
    "            best_ind = thresholds[:, 0].argmin()\n",
    "            best_thr = thresholds[best_ind, 1]\n",
    "\n",
    "            best_imp = thresholds[best_ind, 0]\n",
    "            if (best_thr is None):\n",
    "                self.tree[node_id] = (self.LEAF_TYPE,\n",
    "                                      np.bincount(y).argmax(),\n",
    "                                      np.bincount(y) / y.size)\n",
    "                return\n",
    "\n",
    "            x_l, x_r, y_l, y_r = self.__div_samples(x, y,\n",
    "                                                    feature_ids[best_ind],\n",
    "                                                    best_thr)\n",
    "\n",
    "            if y_l.size == 0 or y_r.size == 0:\n",
    "                self.tree[node_id] = (self.LEAF_TYPE,\n",
    "                                      np.bincount(y).argmax(),\n",
    "                                      np.bincount(y) / y.size)\n",
    "                return\n",
    "\n",
    "            self.tree[node_id] = (self.NON_LEAF_TYPE,\n",
    "                                  feature_ids[best_ind],\n",
    "                                  best_thr)\n",
    "\n",
    "            self.feature_importances_[\n",
    "                feature_ids[best_ind]\n",
    "            ] += self._imp(y) - self._imp(y_r) - self._imp(y_l)\n",
    "            self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "            self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1], dtype=np.float)\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= self.feature_importances_.sum()\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 ms, sys: 0 ns, total: 2.69 ms\n",
      "Wall time: 5.72 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 ms, sys: 294 µs, total: 27.7 ms\n",
      "Wall time: 35.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8968253968253969"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8968253968253969"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('speed-dating-experiment/Speed Dating Data.csv',\n",
    "                 encoding='latin1')\n",
    "df = df.iloc[:, :97]\n",
    "\n",
    "df = df.drop(['id', 'idg', 'condtn', 'position',\n",
    "              'positin1', 'order', 'partner',\n",
    "              'age_o', 'race_o', 'pf_o_att', 'tuition',\n",
    "              'pf_o_sin', 'pf_o_int', 'pf_o_fun',\n",
    "              'pf_o_amb', 'pf_o_sha', 'dec_o',\n",
    "              'attr_o', 'sinc_o', 'intel_o', 'mn_sat',\n",
    "              'fun_o', 'amb_o', 'shar_o', 'like_o',\n",
    "              'prob_o','met_o', 'field', 'undergra',\n",
    "              'from', 'zipcode', 'income', 'sports',\n",
    "              'tvsports','exercise','dining', 'round',\n",
    "              'museums','art','hiking','gaming',\n",
    "              'clubbing','reading','tv','theater',\n",
    "              'movies','concerts','music','shopping',\n",
    "              'yoga', 'expnum'], axis=1)\n",
    "\n",
    "df = df.dropna(subset=['age'])\n",
    "\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "df.field_cd = df.field_cd.astype(np.int)\n",
    "\n",
    "df.race = df.race.astype(np.int)\n",
    "\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)\n",
    "df = df.drop(['career'], axis=1)\n",
    "df.career_c = df.career_c.astype(np.int)\n",
    "\n",
    "df = df.dropna(subset=['imprelig', 'imprace', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'temp_totalsum'] =\\\n",
    "    df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "               'fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "           'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "                'fun1_1', 'amb1_1', 'shar1_1']].T/\n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'temp_totalsum'] =\\\n",
    "    df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "               'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "           'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                'fun2_1', 'amb2_1', 'shar2_1']].T/\n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['temp_totalsum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "    df = df.drop(feat, axis=1)\n",
    "\n",
    "df = df.drop(['wave'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1).dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr',\n",
    "                                          'samerace'], axis=1).dropna()\n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'\n",
    "\n",
    "df_male.pid = df_male.pid.astype(np.int)\n",
    "df_female.pid_f = df_female.pid_f.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_male.join(df_female.set_index('iid_f'), how='right', on='pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_join.loc[:, 'match'].values\n",
    "df_join = df_join.drop(['match', 'iid', 'pid', 'pid_f'], axis=1)\n",
    "data = df_join.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDD_my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "SDD_clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SDD, X_test_SDD, y_train_SDD, y_test_SDD = train_test_split(data, target,\n",
    "                                                    test_size=0.01, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 3.23 ms, total: 124 ms\n",
      "Wall time: 126 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time SDD_clf.fit(X_train_SDD, y_train_SDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 0 ns, total: 1.4 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%time SDD_my_clf.fit(X_train_SDD, y_train_SDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4029850746268657"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=SDD_clf.predict(X_test_SDD), y_true=y_test_SDD, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=SDD_my_clf.predict(X_test_SDD), y_true=y_test_SDD, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn DecisionTreeClassifier:\n",
      "\n",
      "('int_corr', 0.08554163321322455)\n",
      "('age', 0.03332227945042851)\n",
      "('intel1_1', 0.029294935321020392)\n",
      "('amb3_1_f', 0.02781611438956904)\n",
      "('shar1_1_f', 0.02766568903140461)\n",
      "('fun2_1', 0.02604916028016846)\n",
      "('intel1_1_f', 0.025906587377460225)\n",
      "('sinc2_1_f', 0.025816263862292625)\n",
      "('field_cd_f', 0.025763095702396648)\n",
      "('shar2_1_f', 0.025165177380294355)\n",
      "\n",
      "MyDecisionTreeClassifier:\n",
      "\n",
      "('shar1_1', 0.00797441761375645)\n",
      "('amb1_1_f', 0.01906896294144787)\n",
      "('int_corr', 0.08554163321322455)\n",
      "('shar2_1', 0.021566769617078374)\n",
      "('attr3_1', 0.021407228111603723)\n",
      "('shar1_1_f', 0.02766568903140461)\n",
      "('amb1_1', 0.022686319108339927)\n",
      "('imprace', 0.013953473697108776)\n",
      "('age', 0.03332227945042851)\n",
      "('go_out_f', 0.013536544014855371)\n"
     ]
    }
   ],
   "source": [
    "f_idx = np.argsort(SDD_clf.feature_importances_)[::-1]\n",
    "my_f_idx = np.argsort(SDD_my_clf.feature_importances_)[::-1]\n",
    "\n",
    "features = zip(df_join.columns[f_idx][:10], SDD_clf.feature_importances_[f_idx][:10])\n",
    "my_features = zip(df_join.columns[my_f_idx][:10], SDD_clf.feature_importances_[my_f_idx][:10])\n",
    "\n",
    "print('Sklearn DecisionTreeClassifier:\\n', *features, sep='\\n')\n",
    "print('\\nMyDecisionTreeClassifier:\\n', *my_features, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waff/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 95,\n",
       " 'min_samples_split': 6,\n",
       " 'max_depth': 5,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": range(2, 10),\n",
    "    \"min_samples_split\": range(2, 10),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": range(5, 100, 5)}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(model, param_grid, cv=5, n_iter=400)\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
